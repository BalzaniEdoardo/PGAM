{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conscious-cooperative",
   "metadata": {},
   "source": [
    "# GAM decoding\n",
    "Decode distance to target using a B-spline to learn filter shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forced-second",
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to extract pairs, different blocks number\n",
      "no eyetracking...\n",
      "['all', 'reward', 'density', 'ptb', 'microstim', 'landmark', 'replay', 'controlgain', 'firefly_fullON']\n",
      "Succesfully set filter\n",
      "SAVING\n"
     ]
    }
   ],
   "source": [
    "# load  data (requires a pull from the repo to get the pre processing code going)\n",
    "import sys,os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat,savemat\n",
    "import dill\n",
    "sys.path.append('/Users/edoardo/Work/Code/GAM_code/GAM_library')\n",
    "sys.path.append('/Users/edoardo/Work/Code/GAM_code/firefly_utils')\n",
    "from data_handler import data_handler\n",
    "from GAM_library import *\n",
    "\n",
    "# save directory\n",
    "DIRECT = ''\n",
    "\n",
    "min_bin_size = 0.01 # min size of a spike count bin in sec\n",
    "\n",
    "\n",
    "session = 'm53s113'\n",
    "# path to the .mat dataset\n",
    "base_file = '/Volumes/WD_Edo/firefly_analysis/LFP_band/DATASET_accel/'\n",
    "dat = loadmat(os.path.join(base_file,'%s.mat'%(session)))\n",
    "\n",
    "\n",
    "\n",
    "use_eye = 'right'\n",
    "exp_data = data_handler(dat, 'trials_behv', 'units', None, 'behv_stats',\n",
    "                        use_eye=use_eye,extract_fly_and_monkey_xy=True)\n",
    "\n",
    "exp_data.set_filters('all', True)\n",
    "exp_data.filter = exp_data.filter + exp_data.info.get_replay(0,skip_not_ok=False)\n",
    "\n",
    "time_pts, spikes, sm_traj, raw_traj, fly_pos, cov_dict = exp_data.GPFA_YU_preprocessing([('t_targ','t_targ_off',15),('t_targ_off','t_stop',50),('t_stop','t_reward',15)],\n",
    "                                                                                          var_list=['eye_vert','eye_hori','rad_vel','ang_vel','rad_target','ang_target'])\n",
    "\n",
    "idx_trial = np.arange(rate.shape[0])\n",
    "\n",
    "select = exp_data.filter & ((np.diff(time_pts,axis=1) > min_bin_size).prod(axis=1) > 0)\n",
    "\n",
    "idx_trial = idx_trial[select]\n",
    "spikes = spikes[select]\n",
    "time_pts = time_pts[select]\n",
    "print('SAVING') # matlab file because it will be an input to GPFA matlab code\n",
    "savemat(os.path.join(DIRECT,'test_%s_gpfa.mat'%session), mdict={'dat': {'spikes':spikes,'timeDiscr':time_pts,'trialId':idx_trial},\n",
    "                                                                    'sm_trajectory':sm_traj,'raw_trajectory':raw_traj,\n",
    "                                                                    'fly_pos':fly_pos,'var_struct':cov_dict,'info_trial':exp_data.info.trial_type})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-montreal",
   "metadata": {},
   "source": [
    "# Import, create model matrix using B-splines, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "visible-speed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52976,) (52976, 81) (688, 81, 77)\n",
      "unit 0\n",
      "unit 15\n",
      "unit 30\n",
      "unit 45\n",
      "unit 60\n",
      "unit 75\n",
      "hstack: 12.94039708199989 sec\n",
      "tranform to full matrix:  0.2647489270002552 sec\n"
     ]
    }
   ],
   "source": [
    "# import some library, create the data_handler object that will generate the b-spline\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as sts\n",
    "\n",
    "rad_target = cov_dict['rad_target']\n",
    "\n",
    "\n",
    "# # filter the trials\n",
    "rad_target = rad_target[idx_trial,:]\n",
    "# raw_traj = raw_traj[idx_trial,:,:]\n",
    "\n",
    "# create a GAM stacking the inputs\n",
    "Y = rad_target.reshape(rad_target.shape[0]*rad_target.shape[1])\n",
    "trial_id_stacked = np.zeros(Y.shape[0],dtype=int)\n",
    "cc = 0\n",
    "for tr in idx_trial:\n",
    "    trial_id_stacked[cc:cc+rad_target.shape[1]] = tr\n",
    "    cc += rad_target.shape[1]\n",
    "X_spk = spikes.transpose([0,2,1]).reshape(spikes.shape[0]*spikes.shape[2],spikes.shape[1])\n",
    "\n",
    "\n",
    "# loop over units and generate the handler\n",
    "non_nan = (~np.isnan(Y))\n",
    "\n",
    "sm_handler = smooths_handler()\n",
    "knots = np.linspace(-20,20,5)\n",
    "knots = np.hstack(([knots[0]] * 3,\n",
    "                   knots,\n",
    "                   [knots[-1]] * 3\n",
    "                   ))\n",
    "\n",
    "is_temporal_kernel = True\n",
    "kernel_direction = 0\n",
    "\n",
    "\n",
    "for k in range(X_spk.shape[1]):\n",
    "    if k%15 == 0:\n",
    "        print('unit %d'%k)\n",
    "    sm_handler.add_smooth('neu_%d'%k, [X_spk[non_nan,k]], ord=4, knots=[knots],\n",
    "                               knots_num=None, perc_out_range=None,\n",
    "                               is_cyclic=[False], lam=50,\n",
    "                               penalty_type='der',\n",
    "                               der=2,\n",
    "                               trial_idx=trial_id_stacked[non_nan], time_bin=1.,\n",
    "                               is_temporal_kernel=is_temporal_kernel,\n",
    "                               kernel_length=20,\n",
    "                               kernel_direction=kernel_direction, ord_AD=3, ad_knots=4,\n",
    "                               repeat_extreme_knots=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y = Y[non_nan]\n",
    "trial_id_stacked = trial_id_stacked[non_nan]\n",
    "\n",
    "# separate test and train\n",
    "unq_trials = np.unique(trial_id_stacked)\n",
    "test_trials = unq_trials[::10]\n",
    "train_trials = np.array(list(set(unq_trials).difference(set(test_trials))))\n",
    "\n",
    "bool_train = np.zeros(trial_id_stacked.shape[0],dtype=bool)\n",
    "for tr in train_trials:\n",
    "    bool_train[trial_id_stacked==tr] = True\n",
    "bool_test = ~bool_train\n",
    "\n",
    "# get the model matrix and the smoothing penalization\n",
    "X,idx_dict = sm_handler.get_exog_mat(sm_handler.smooths_var)\n",
    "M = sm_handler.get_penalty_agumented(sm_handler.smooths_var)\n",
    "Pen = np.dot(M.T,M)\n",
    "# to change the penalization constant we could set \n",
    "\n",
    "# penalized regression (using formula for the estimator, could be unstable...\n",
    "# SVD based computation would be more robyst)\n",
    "beta = np.dot(np.linalg.pinv(np.dot(X[bool_train].T,X[bool_train])+Pen),np.dot(X[bool_train].T,Y[bool_train]))\n",
    "\n",
    "\n",
    "# estimate covariance (not great since the smoothing prior is not estimated)\n",
    "M = np.array(M, dtype=np.float64)\n",
    "Q, R = np.linalg.qr(X, 'reduced')\n",
    "U, s, V_T = linalg.svd(np.vstack((R, M[:, :])))\n",
    "\n",
    "# remove low val singolar values\n",
    "i_rem = np.where(s < 10 ** (-8) * s.max())[0]\n",
    "\n",
    "# remove cols\n",
    "s = np.delete(s, i_rem, 0)\n",
    "U = np.delete(U, i_rem, 1)\n",
    "V_T = np.delete(V_T, i_rem, 0)\n",
    "\n",
    "# create diag mat\n",
    "di = np.diag_indices(s.shape[0])\n",
    "D2inv = np.zeros((s.shape[0], s.shape[0]))\n",
    "D2inv[di] = 1 / s ** 2\n",
    "D2inv = np.matrix(D2inv)\n",
    "V_T = np.matrix(V_T)\n",
    "\n",
    "cov_beta = np.array(V_T.T * D2inv * V_T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-apollo",
   "metadata": {},
   "source": [
    "# Plot some example filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.suptitle('depth')\n",
    "for k in range(25):\n",
    "    plt.subplot(5,5,k+1)\n",
    "    BK = sm_handler.smooths_dict['neu_%d'%k].basis_kernel.toarray()\n",
    "    func = np.dot(BK[:,:-1], beta[idx_dict['neu_%d'%k]])\n",
    "    plt.plot(func)\n",
    "    se_y = np.sqrt(\n",
    "        np.sum(np.dot(BK[:, :-1], cov_beta[idx_dict['neu_%d' % k], :][:, idx_dict['neu_%d' % k]]) * BK[:, :-1], axis=1))\n",
    "    norm = sts.norm()\n",
    "    se_y = se_y * norm.ppf(1 - (1 - 0.95) * 0.5)\n",
    "    plt.fill_between(range(len(func)),func - se_y,func + se_y,alpha=0.5,color='b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-valley",
   "metadata": {},
   "source": [
    "# Compute R^2 and example cv-decoded distance to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.dot(X[bool_test],beta)\n",
    "RSS = np.sum((predict - Y[bool_test])**2)\n",
    "TSS = np.sum((Y[bool_test] - np.mean(Y[bool_test]))**2)\n",
    "adj_r2 = 1-(non_nan.sum()-1)/(non_nan.sum() - X.shape[1] - 1) * RSS/TSS\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.suptitle('rad_dist reconstruction - cv R^2: %.3f'%adj_r2)\n",
    "\n",
    "for k in range(25):\n",
    "    plt.subplot(5,5,k+1)\n",
    "    tr = test_trials[k]\n",
    "    sel = trial_id_stacked[bool_test] == tr\n",
    "    plt.plot(Y[bool_test][sel])\n",
    "    plt.plot(predict_depth[sel],'r')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
