# initial classes and code
import numpy as np
import os, sys, re
from data_handler import *
from scipy.io import loadmat
from copy import deepcopy
import bisect
from scipy.interpolate import interp1d
from behav_class import emptyStruct

# color_left = np.array([191,228,128])/255.
# color_center = np.array([148,168,208])/255.
# color_right = np.array([251, 182, 209.]) / 255.
#

class fireFly_dataPreproc(data_handler):
    """
    This containers will load the math file containing the task variables and the <br>
    counts. It will add specific preprocessing method that will simplify the re-binning and<br>
    formatting of the data.
    """

    def __init__(self, filepath, flyON_dur=0.3, pre_trial_dur=0.2, post_trial_dur=0.2):

        re.findall('m\d+s\d+', filepath)
        session = re.findall('m\d+s\d+', filepath)[0]

        # keys in the mat file generated by the preprocessing script of  K.
        behav_stat_key = 'behv_stats'
        spike_key = 'units'
        behav_dat_key = 'trials_behv'
        lfp_key = None# 'lfps'

        use_left_eye = ['53s48']

        if session in use_left_eye:
            use_eye = 'left'
        else:
            use_eye = 'right'

        # presence rate params
        occupancy_bin_sec = 60  # at least one spike per min
        occupancy_rate_th = 0.1  # hz

        linearprobe_sampling_fq = 20000
        utah_array_sampling_fq = 30000

        dat = loadmat(filepath)

        super(fireFly_dataPreproc, self).__init__(dat, behav_dat_key, spike_key, lfp_key, behav_stat_key,
                                                  pre_trial_dur=pre_trial_dur,
                                                  post_trial_dur=post_trial_dur,
                                                  lfp_beta=None, lfp_alpha=None, lfp_theta=None,
                                                  extract_lfp_phase=False,
                                                  use_eye=use_eye, fhLFP='', extract_fly_and_monkey_xy=True,
                                                  flyON_dur=flyON_dur)

        self.set_filters('all', True)
        self.preProcessed = None
        return

    def setInitialCond(self, condition='noMovement', init_event='t_flyON'):
        condList = ['noMovement', 'maxSpeed']
        if  not condition in condList:
            raise ValueError('Condition "%s" is not coded for' % condition)

        if init_event == 't_flyON':
            ev_dict = {}
            for tr in self.behav.events.t_flyOFF.keys():
                ev_dict[tr] = self.behav.events.t_flyOFF[tr] - self.behav.flyON_dur
        else:
            try:
                ev_dict = self.behav.events.__dict__[init_event]
            except KeyError:
                raise KeyError('Event "%s" was not loaded'%init_event)

        if condition == 'noMovement':
            # filter for trial where velocity is null at the event
            for tr in self.behav.continuous.rad_vel.keys():
                ts = self.behav.time_stamps[tr]
                vel = self.behav.continuous.rad_vel[tr]
                angvel = self.behav.continuous.ang_vel[tr]
                iidx = bisect.bisect_left(ts, ev_dict[tr])
                # this params are used for start and stop detection
                if (vel[iidx] > 5) and (angvel[iidx] > 3):
                    self.filter[tr] = False


        if condition == 'maxSpeed':
            mxSpeed = np.nanpercentile(np.hstack(list(self.behav.continuous.rad_vel.values())),95)
            print('SPEED THRRESHOLD: ',mxSpeed)
            # filter for trial where velocity is null at the event
            for tr in self.behav.continuous.rad_vel.keys():
                ts = self.behav.time_stamps[tr]
                vel = self.behav.continuous.rad_vel[tr]
                angvel = self.behav.continuous.ang_vel[tr]
                iidx = bisect.bisect_left(ts, ev_dict[tr])
                if (vel[iidx] < mxSpeed) or (np.abs(angvel[iidx]) > 10):
                    self.filter[tr] = False

        print('set filter for initial condition, trial matching:',self.filter.sum())

    def preProcPGPFA(self, binMs=20, init_event='t_flyON', final_event='t_stop', printEndString=True, smooth=False,
                     filt_window=None):

        # get initial event dict
        if init_event == 't_flyON':
            ev0_dict = {}
            for tr in self.behav.events.t_flyOFF.keys():
                ev0_dict[tr] = self.behav.events.t_flyOFF[tr] - self.behav.flyON_dur

            ev0 = dict_to_vec(ev0_dict)
        else:
            try:
                ev0_dict = self.behav.events.__dict__[init_event]
            except KeyError:
                raise KeyError('Event "%s" was not loaded'%init_event)

        # get final event dict
        try:
            ev1_dict = self.behav.events.__dict__[final_event]
        except KeyError:
            raise KeyError('Event "%s" was not loaded' % final_event)

        ev1 = dict_to_vec(ev1_dict)

        tr_sel = np.arange(self.behav.n_trials,dtype=int)[self.filter]

        bin_ts = self.time_stamps_rebin(binwidth_ms=binMs)
        if not smooth:

            bin_list = self.spikes.bin_spikes(bin_ts, t_start=ev0_dict, t_stop=ev1_dict, select=self.filter)
            bin_spk = self.spikes.binned_spikes
        else:
            ext_ev0 = {}
            ext_ev1 = {}
            for tr in ev0_dict.keys():
                ext_ev0[tr] = ev0_dict[tr] - self.behav.pre_trial_dur
                ext_ev1[tr] = ev1_dict[tr] + self.behav.post_trial_dur
            tt_start = dict_to_vec(ext_ev0)
            tt_stop = dict_to_vec(ext_ev1)
            time_dict = self.spikes.bin_spikes(self.behav.time_stamps, t_start=tt_start, t_stop=tt_stop, select=self.filter)
            DT = time_dict[list(time_dict.keys())[0]][1] - time_dict[list(time_dict.keys())[0]][0]

            sm_spikes = np.zeros((self.spikes.binned_spikes.shape[0], tr_sel.shape[0]), dtype=object)
            for idxtr in range(tr_sel.shape[0]):
                #tr = tr_sel[idxtr]
                for un in range(self.spikes.binned_spikes.shape[0]):
                    sm_spikes[un, idxtr] = np.convolve(self.spikes.binned_spikes[un, idxtr] / DT, filt_window, mode='same')

            # use the proper binning in ms
            bin_list = self.spikes.bin_spikes(bin_ts, t_start=ev0_dict, t_stop=ev1_dict, select=self.filter)

            # interp to the right size
            bin_spk = np.zeros(sm_spikes.shape, dtype=object)
            for idxtr in range(tr_sel.shape[0]):
                tr = tr_sel[idxtr]
                for un in range(self.spikes.binned_spikes.shape[0]):
                    interp = interp1d(time_dict[tr], sm_spikes[un,idxtr])
                    bin_spk[un, idxtr] = interp(bin_list[tr])

        self.preProcessed = emptyStruct()
        self.preProcessed.numTrials = tr_sel.shape[0]
        self.preProcessed.ydim = self.spikes.binned_spikes.shape[0]

        # create a container for the behav correlates
        tw_correlates = {}
        for var in self.behav.continuous.__dict__.keys():
            tw_correlates[var] = np.zeros((tr_sel.shape[0],), dtype=object)

        data = []
        cc = 0
        for tr in tr_sel:
            T = bin_spk[0, cc].shape[0]
            tmp = np.zeros((self.preProcessed.ydim, T))
            for un in range(self.preProcessed.ydim):
                tmp[un, :] = bin_spk[un, cc]
            data += [{'Y': deepcopy(tmp)}]

            # interp variables
            if tr == tr_sel[0]:
                list_pop = []
            for var in self.behav.continuous.__dict__.keys():
                if ('_fly' in var):
                    continue
                try:
                    time_pts = self.behav.time_stamps[tr]
                    y_val = self.behav.continuous.__dict__[var][tr]
                    non_nan = ~np.isnan(y_val)
                    intrp = interp1d(time_pts[non_nan], y_val[non_nan], bounds_error=False)
                    tw_correlates[var][cc] = intrp(bin_list[tr_sel[cc]])
                except:
                    if tr == tr_sel[0]:
                        print('could not extract %s!'%var)
                        list_pop += [var]

            cc += 1
        for var in list_pop:
            tw_correlates.pop(var)

        self.preProcessed.data = data
        self.preProcessed.binSize = binMs
        self.preProcessed.trialDur = None
        self.preProcessed.T = None
        self.preProcessed.covariates = tw_correlates
        self.preprocessing_type = 'P-GPFA'
        self.preProcessed.trialId = tr_sel
        if printEndString:
            print('Preprocessing for P-GPFA completed')
        return

    def preProcPCA(self, binMs=20, init_event='t_flyON', final_event='t_stop', smooth=False,filt_window=None):
        self.preProcPGPFA(binMs=binMs, init_event=init_event, final_event=final_event,printEndString=False, smooth=smooth,
                          filt_window=filt_window)

        # concatenate all data to make it simpler to use with PCA/FA or similar models
        stackData = []
        trialId = []
        stackedCovariate = {}
        for key in self.preProcessed.covariates.keys():
            stackedCovariate[key] = []
        cc = 0
        for xx in self.preProcessed.data:
            stackData += [xx['Y']]
            trialId += [self.preProcessed.trialId[cc]]*xx['Y'].shape[1]
            for key in self.preProcessed.covariates.keys():
                stackedCovariate[key] += [self.preProcessed.covariates[key][cc]]
            cc += 1
        del xx
        stackData = np.hstack(stackData)
        trialId = np.array(trialId,dtype=int)
        for key in self.preProcessed.covariates.keys():
            stackedCovariate[key] = np.hstack(stackedCovariate[key])

        self.preProcessed = emptyStruct()
        self.preProcessed.numTrials = np.unique(trialId).shape[0]
        self.preProcessed.ydim = self.spikes.binned_spikes.shape[0]
        self.preProcessed.data = stackData
        self.preProcessed.binSize = binMs
        self.preProcessed.trialDur = None
        self.preProcessed.T = None
        self.preProcessed.covariates = stackedCovariate
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId

    def preProcGPFA_timeWarp(self, list_timepoints=None, var_list=[]):
        """

        :param list_timepoints: a list containing of tuple of three elements: [(ev0, ev1, T0), (ev1, ev2, T1), ...]
            * $ev_j$ : string, name of first event  (e.g. t_start, t_flyON...)
            * $ev_{j+1}$ : string, name of second event (needs to follow ev0)
            * Tj number of time points in which to bin the interval between $ev_j$ and $ev_{j+1}$
            note that the last event of an interval must coincide with the first event of the following interval
        :param var_list: list of stringss, variable names to be time warped
        :return:
        """
        tp_matrix, rate_tensor, sm_traj, raw_traj, fly_pos, tw_correlates, trialId =\
            self.GPFA_YU_preprocessing(list_timepoints=list_timepoints, var_list=var_list)

        trialKeep = ~np.isnan(rate_tensor.sum(axis=(1,2)))
        self.preProcessed = emptyStruct()
        self.preProcessed.data = rate_tensor[trialKeep]
        self.preProcessed.covariates = {}
        for var in tw_correlates.keys():
            self.preProcessed.covariates[var] = tw_correlates[var][trialKeep]

        trialId = trialId[trialKeep]
        self.preProcessed.ydim = rate_tensor.shape[1]
        self.preProcessed.numTrials = np.unique(trialId).shape[0]
        self.preProcessed.binSize = None
        self.preProcessed.trialDur = None
        self.preProcessed.T = tp_matrix[trialKeep]
        self.preProcessed.sm_trajectory = sm_traj[trialKeep]
        self.preProcessed.raw_trajecory = raw_traj[trialKeep]
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId
        self.preProcessed.fly_pos = fly_pos[trialKeep]
        self.preProcessed.descr_data = \
        """
        Description of the variable structure:
             \t*) self.preProcessed.data : (# trial x # units x # time points) tensor of firing rate in Hz x time interval
             \t*) self.preProcessed.T : (# trial x # time points), centers of each time interval in seconds
             \t*) self.preProcessed.raw_trajectory : (# trial x 2 x # time points), raw x,y trajectory of the monkey on the sceen in cm
             \t*) self.preProcessed.raw_trajectory : same as above but smooth
             \t*) self.preProcessed.covariates : dictionary, keys are the task variable names, values:
             \t\t (# trials x # time points) time warped task variable
        """
        print('Finished preprocessing for GPFA Byron YU code with time warping')


    def preProcPCA_timeWarp(self, list_timepoints=None, var_list=[],pcaPrep=True, smooth=True,
                            sqrtIfPCA=True, filt_window=None):
        """

        :param list_timepoints: a list containing of tuple of three elements: [(ev0, ev1, T0), (ev1, ev2, T1), ...]
            * $ev_j$ : string, name of first event  (e.g. t_start, t_flyON...)
            * $ev_{j+1}$ : string, name of second event (needs to follow ev0)
            * Tj number of time points in which to bin the interval between $ev_j$ and $ev_{j+1}$
            note that the last event of an interval must coincide with the first event of the following interval
        :param var_list: list of stringss, variable names to be time warped
        :return:
        """
        tp_matrix, rate_tensor, sm_traj, raw_traj, fly_pos, tw_correlates, trialId =\
            self.GPFA_YU_preprocessing(list_timepoints=list_timepoints, var_list=var_list,
                                       pcaPrep=pcaPrep, sqrtIfPCA=sqrtIfPCA, filt_window=filt_window,
                                       smooth=smooth)

        trialKeep = ~np.isnan(rate_tensor.sum(axis=(1,2)))
        self.preProcessed = emptyStruct()
        rate_tensor = rate_tensor[trialKeep]

        # create a rate matrix (# units x # time points stacked)
        trialId = np.repeat(trialId, rate_tensor.shape[2])
        rate_tensor = rate_tensor.transpose((1, 0, 2))
        rate_tensor = rate_tensor.reshape(rate_tensor.shape[0], -1)

        self.preProcessed.data = rate_tensor
        self.preProcessed.covariates = {}
        for var in tw_correlates.keys():
            self.preProcessed.covariates[var] = tw_correlates[var][trialKeep]

        # trialId = trialId[trialKeep]
        self.preProcessed.ydim = rate_tensor.shape[0]
        self.preProcessed.numTrials = np.unique(trialId).shape[0]
        self.preProcessed.binSize = None
        self.preProcessed.trialDur = None
        self.preProcessed.T = tp_matrix[trialKeep]
        self.preProcessed.sm_trajectory = sm_traj[trialKeep]
        self.preProcessed.raw_trajecory = raw_traj[trialKeep]
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId
        self.preProcessed.fly_pos = fly_pos[trialKeep]
        self.preProcessed.descr_data = \
        """
        Description of the variable structure:
             \t*) self.preProcessed.data : (# trial x # units x # time points) tensor of firing rate in Hz x time interval
             \t*) self.preProcessed.T : (# trial x # time points), centers of each time interval in seconds
             \t*) self.preProcessed.raw_trajectory : (# trial x 2 x # time points), raw x,y trajectory of the monkey on the sceen in cm
             \t*) self.preProcessed.raw_trajectory : same as above but smooth
             \t*) self.preProcessed.covariates : dictionary, keys are the task variable names, values:
             \t\t (# trials x # time points) time warped task variable
        """
        print('Finished preprocessing for PCA with time warping')


    def preProcGPFA(self, binMs=20, init_event='t_flyON', final_event='t_stop'):
        """

        :param list_timepoints: a list containing of tuple of three elements: [(ev0, ev1, T0), (ev1, ev2, T1), ...]
            * $ev_j$ : string, name of first event  (e.g. t_start, t_flyON...)
            * $ev_{j+1}$ : string, name of second event (needs to follow ev0)
            * Tj number of time points in which to bin the interval between $ev_j$ and $ev_{j+1}$
            note that the last event of an interval must coincide with the first event of the following interval
        :param var_list: list of stringss, variable names to be time warped
        :return:
        """

        var_list = list(self.behav.continuous.__dict__.keys())
        if 'x_fly' in var_list:
            var_list.remove('x_fly')
            var_list.remove('y_fly')
        # get initial event dict
        if init_event == 't_flyON':
            ev0_dict = {}
            for tr in self.behav.events.t_flyOFF.keys():
                ev0_dict[tr] = self.behav.events.t_flyOFF[tr] - self.behav.flyON_dur
        else:
            try:
                ev0_dict = self.behav.events.__dict__[init_event]
            except KeyError:
                raise KeyError('Event "%s" was not loaded' % init_event)

        # get final event dict
        try:
            ev1_dict = self.behav.events.__dict__[final_event]
        except KeyError:
            raise KeyError('Event "%s" was not loaded' % final_event)


        #GPFA_YU_preprocessing_noTW(self, t_start, t_stop, var_list=[],binwidth_ms=20)
        tp_matrix, rate_tensor, sm_traj, raw_traj, fly_pos, tw_correlates, trialId =\
            self.GPFA_YU_preprocessing_noTW(ev0_dict, ev1_dict, var_list=var_list, binwidth_ms=binMs)

        self.preProcessed = emptyStruct()
        self.preProcessed.data = rate_tensor#[trialKeep]
        self.preProcessed.covariates = {}
        for var in tw_correlates.keys():
            self.preProcessed.covariates[var] = tw_correlates[var]#[trialKeep]

        trialId = trialId#[trialKeep]
        self.preProcessed.ydim = rate_tensor[0].shape[0]
        self.preProcessed.numTrials = len(rate_tensor.keys())
        self.preProcessed.binSize = None
        self.preProcessed.trialDur = None
        self.preProcessed.T = tp_matrix
        self.preProcessed.sm_trajectory = sm_traj
        self.preProcessed.raw_trajecory = raw_traj
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId
        self.preProcessed.fly_pos = fly_pos
        self.preProcessed.descr_data = \
        """
        Description of the variable structure:
             \t*) self.preProcessed.data :  dictionary containing (# units x # time points) tensor of spike counts, one matrix per trial
             \t*) self.preProcessed.T : dictionary containing (# time points)
             \t*) self.preProcessed.raw_trajectory : (# trial x 2 x # time points), raw x,y trajectory of the monkey on the sceen in cm
             \t*) self.preProcessed.raw_trajectory : same as above but smooth
             \t*) self.preProcessed.covariates : dictionary, keys are the task variable names, values:
             \t\t (# trials x # time points) time warped task variable
        """
        print('Finished preprocessing for GPFA Byron YU code with time warping')


    def time_stamps_rebin(self, binwidth_ms=20):
        rebin = {}
        for tr in self.behav.time_stamps.keys():
            ts = self.behav.time_stamps[tr]
            tp_num = np.floor((ts[-1] - ts[0]) * 1000 / (binwidth_ms))
            rebin[tr] = ts[0] + np.arange(tp_num) * binwidth_ms / 1000.
        return rebin